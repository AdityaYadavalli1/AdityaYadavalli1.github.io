---
---

@string{aps = {American Physical Society,}}

@inproceedings{Shelly2022SLT,
selected={true},
author={Jain, Shelly* and Yadavalli, Aditya* and Mirishkar, Ganesh and Vuppala, Anil Kumar},
abbr={SLT},
booktitle={IEEE Spoken Language Technology Workshop}, 
title={How Do Phonological Properties Affect Bilingual Automatic Speech Recognition?},
year={2022}}

@inproceedings{Aditya2022Interspeech,
selected={true},
bibtex_show={true},
abstract={Conventional Automatic Speech Recognition (ASR) systems are susceptible to dialect variations within a language, thereby adversely affecting the ASR. Therefore, the current practice is to use dialect-specific ASRs. However, dialect-specific information or data is hard to obtain making it difficult to build dialect-specific ASRs. Furthermore, it is cumbersome to maintain multiple dialect-specific ASR systems for each language. We build a unified multi-dialect End-to-End ASR that removes the need for a dialect recognition block and the need to maintain multiple dialect-specific ASRs for three Telugu regional dialects: Telangana, Coastal Andhra, and Rayalaseema. We find that pooling the data and training a multi-dialect ASR benefits the low-resource dialect the most -- an improvement of over 9.71% in relative Word Error Rate (WER). Subsequently, we experiment with multi-task ASRs where the primary task is to transcribe the audio and the secondary task is to predict the dialect. We do this by adding a Dialect ID to the output targets. Such a model outperforms naive multi-dialect ASRs by up to 8.24% in relative WER. Additionally, we test this model on a dialect recognition task and find that it outperforms strong baselines by 6.14% in accuracy.},
author={Yadavalli, Aditya and Mirishkar, Ganesh and Vuppala, Anil Kumar},
pdf={https://www.isca-speech.org/archive/interspeech_2022/yadavalli22_interspeech.html},
abbr={Interspeech},
booktitle={Proc. Interspeech}, 
title={Multi-Task End-to-End Model for Telugu Dialect and Speech Recognition},
pages={1387--1391},
doi={10.21437/Interspeech.2022-10739},
year={2022}}

@inproceedings{Aditya2022NAACLSRW,
selected={true},
bibtex_show={true},
abstract = {Previous research has found that Acoustic Models (AM) of an Automatic Speech Recognition (ASR) system are susceptible to dialect variations within a language, thereby adversely affecting the ASR. To counter this, researchers have proposed to build a dialect-specific AM while keeping the Language Model (LM) constant for all the dialects. This study explores the effect of dialect mismatched LM by considering three different Telugu regional dialects: Telangana, Coastal Andhra, and Rayalaseema. We show that dialect variations that surface in the form of a different lexicon, grammar, and occasionally semantics can significantly degrade the performance of the LM under mismatched conditions. Therefore, this degradation has an adverse effect on the ASR even when dialect-specific AM is used. We show a degradation of up to 13.13 perplexity points when LM is used under mismatched conditions. Furthermore, we show a degradation of over 9{\%} and over 15{\%} in Character Error Rate (CER) and Word Error Rate (WER), respectively, in the ASR systems when using mismatched LMs over matched LMs.},
author={Yadavalli, Aditya and Mirishkar, Ganesh and Vuppala, Anil Kumar}, 
pdf={https://aclanthology.org/2022.naacl-srw.36/}, 
booktitle={North American Chapter of the Association of Computational Linguistics Student Research Workshop}, 
title={Exploring the Effect of Dialect Mismatched Language Models in Telugu
Automatic Speech Recognition}, 
abbr={NAACL-SRW},
publisher = {Association for Computational Linguistics (ACL)},
year={2022}}

@inproceedings{Aditya2022IC3,
selected={true}, 
author={Aditya Yadavalli and Shelly Jain and Ganesh Mirishkar and Anil Kumar Vuppala}, 
year = {2022},
abbr={IC3},
booktitle = {2022 Thirteenth International Conference on Contemporary Computing (IC3-2022)},   
title={Investigation of Subword-Based Bilingual Automatic Speech Recognition for Indian Languages}, 
year={2022},
location = {Noida, India},
series = {IC3 '22}}

@inproceedings{Shelly2021ICON,
  bibtex_show={true},
  title = {{IE-CPS Lexicon}: An Automatic Speech Recognition Oriented Indian English Pronunciation Dictionary},
  booktitle = {Proceedings of the 18th International Conference on Natural Language Processing (ICON)},
  author = {Jain, Shelly* and Yadavalli, Aditya* and Mirishkar, Ganesh* and Yarra, Chiranjeevi and Vuppala, Anil Kumar},
  year = {2021},
  abbr={ICON},
  publisher = {NLP Association of India (NLPAI)},
  eventtitle = {Proceedings of the 18th International Conference on Natural Language Processing (ICON)}
}

@inproceedings{MirishkarHybrid,
  bibtex_show={true},
  title = {An Investigation of Hybrid architectures for Low Resource Multilingual Speech Recognition system in Indian context},
  booktitle = {Proceedings of the 18th International Conference on Natural Language Processing (ICON)},
  author = {Mirishkar, Ganesh and Yadavalli, Aditya and Vuppala, Anil Kumar},
  year = {2021},
  abbr={ICON},
  publisher = {NLP Association of India (NLPAI)},
  eventtitle = {Proceedings of the 18th International Conference on Natural Language Processing (ICON)}
}

@inproceedings{10.1145/3474124.3474162,
author = {Vats, Nayan Anand and Yadavalli, Aditya and Gurugubelli, Krishna and Vuppala, Anil Kumar},
title = {ACOUSTIC FEATURES, BERT Model AND THEIR COMPLEMENTARY NATURE FOR ALZHEIMER’S DEMENTIA DETECTION},
year = {2021},
abbr={IC3},
bibtex_show={true},
isbn = {9781450389204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474124.3474162},
doi = {10.1145/3474124.3474162},
abstract = {Dementia is a syndrome chronic or progressive that usually affects the cognitive functioning of the subjects. Alzheimer’s, a neurodegenerative disorder, is the leading cause of dementia. One of the many symptoms of Alzheimer’s Dementia is the inability to speak and understand language clearly. The last decade has seen a surge in the research done in Alzheimer’s Dementia detection using Linguistics and acoustic features. This paper takes up the Alzheimer’s Dementia classification task of ADReSS INTERSPEECH-2020 challenge, ”Alzheimer’s Dementia Recognition through Spontaneous Speech: The ADReSS Challenge”. It uses eight different acoustic features to find the attributes in the human speech production system (vocal track and excitation source) affected by Alzheimer’s Dementia. In this study, the Alzheimer’s dementia classification is performed using five different Machine Learning models using ADReSS INTERSPEECH-2020 challenge dataset. Since most of the studies in the previous literature have used linguistic features successfully for Alzheimer’s dementia classification, the current study also demonstrates the performance of the BERT model for the dementia classification task. The maximum accuracy obtained by the acoustic feature is 64.5\%, and the BERT Model provides a classification accuracy of 79.1\% over the test dataset. Finally, the score-level fusion of the acoustic model with the BERT Model shows an improvement of 6.1\% classification accuracy over the BERT Model, which indicates the complementary nature of acoustic features to linguistic features.},
booktitle = {2021 Thirteenth International Conference on Contemporary Computing (IC3-2021)},
pages = {267–272},
numpages = {6},
pdf={https://dl.acm.org/doi/10.1145/3474124.3474162},
keywords = {Dementia, Alzheimer’s, BERT, Acoustic features},
location = {Noida, India},
series = {IC3 '21}
}
