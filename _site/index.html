<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Aditya  Yadavalli</title>
    <meta name="author" content="Aditya  Yadavalli" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Social Icons -->
          <div class="navbar-brand social">
            <a href="mailto:%61%64%69%74%79%61.%79%61%64%61%76%61%6C%6C%69@%72%65%73%65%61%72%63%68.%69%69%69%74.%61%63.%69%6E" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://www.semanticscholar.org/author/Aditya-Yadavalli/151482275" title="Semantic Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-semantic-scholar"></i></a>
            <a href="https://github.com/AdityaYadavalli1" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/aditya-yadavalli-02b7391ab" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/AdityaYadavall2" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            
          </div>
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/assets/pdf/Aditya_CV.pdf">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">Aditya</span>  Yadavalli
          </h1>
          <p class="desc">Speech/NLP Engineer at <a href="https://karya.in" target="_blank" rel="noopener noreferrer">Karya</a></p>
        </header>

        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid z-depth-1 rounded" src="/assets/img/IMG_6620.JPG" width="auto" height="auto" alt="IMG_6620.JPG">

  </picture>

</figure>

            <div class="address">
              <p> PhD Applicant for Fall '24 </p> <p>Let me know if you think I am a good fit for your group!</p>
            </div>
          </div>

          <div class="clearfix">
            <!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

<p>I am a Speech/NLP Engineer at Karya. Here, I work on data processing pipelines, quality estimation of crowdsourced datasets, and building assistive tools for crowdsource workers.</p>

<p>I am also a visiting researcher at Case Western Reserve University (CWRU), where I collaborate with <a href="https://veratobin.org" target="_blank" rel="noopener noreferrer">Prof. Vera Tobin</a>. Here, I work on evaluating NLP models trained on Child Directed Speech (CDS) and am looking to establish common mistakes that humans and NLP models make when acquiring a new language.</p>

<p>In my free time, I volunteer at <a href="https://www.masakhane.io" target="_blank" rel="noopener noreferrer">Masakhane</a> – a group dedicated to work on improving NLP models for Africa. Along with the rest in the group, I explore how current NLP models exhibit bias when they encounter African languages and accents and how we can mitigate this bias.</p>

<p>Previously, I was a dual degree student at <a href="https://www.iiit.ac.in" target="_blank" rel="noopener noreferrer">IIIT Hyderabad</a>, where I pursued B.Tech. (Hons) in Computer Science &amp; M.S. by Research in Computational Linguistics. For my M.S. thesis, I explored how closely related languages can be used to improve the performance of low-resource languages at Speech Processing Lab (SPL) with <a href="https://www.iiit.ac.in/people/faculty/anilvuppala/" target="_blank" rel="noopener noreferrer">Prof. Anil Kumar Vuppala</a>.</p>

<!-- I am a 5th year dual degree student at [IIIT Hyderabad](https://www.iiit.ac.in) pursuing a B.Tech (Hons) in Computer Science & M.S. by Research in Computational Linguistics. I will be (hope to!) graduating in July.

Broadly, I am interested in Natural Language Processing (NLP) and Machine Learning. More specifically, I am interested in low-resource NLP. As part of my Masters, I am exploring how closely related languages can be used to improve the performance of low-resource languages at Speech Processing Lab (SPL) under the guidance of [Prof. Anil Kumar Vuppala](https://www.iiit.ac.in/people/faculty/anilvuppala/). -->

<p>When not at work, you can find me discussing cricket or picking up obscure trivia that no one cares about.</p>

          </div>

          <!-- News -->          
          <div class="news">
            <h2>news</h2>
            <div class="table-responsive" style="max-height: 20vw">
              <table class="table table-sm table-borderless">
               
                <tr>
                  <th scope="row">Oct 4, 2023</th>
                  <td>
                    Paper titled <a href="https://arxiv.org/pdf/2310.00274.pdf" target="_blank" rel="noopener noreferrer">AfriSpeech-200: Pan-African Accented Speech Dataset for Clinical and General Domain ASR</a> accepted in TACL &amp; will be presented at EMNLP 2023!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 4, 2023</th>
                  <td>
                    Paper titled <a href="https://arxiv.org/pdf/2305.19589.pdf" target="_blank" rel="noopener noreferrer">SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT</a> accepted at <a href="https://2023.aclweb.org" target="_blank" rel="noopener noreferrer">ACL 2023</a> <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 4, 2023</th>
                  <td>
                    Paper titled <a href="https://aclanthology.org/2023.findings-acl.174/" target="_blank" rel="noopener noreferrer">X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents</a> accepted in ACL Findings!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Nov 11, 2022</th>
                  <td>
                    Defended my MS thesis! Thanks to my panel – <a href="https://sites.google.com/site/kishoreprahallad/?pli=1" target="_blank" rel="noopener noreferrer">Dr. Kishore Prahallad</a> and <a href="https://www.iiit.ac.in/people/faculty/Chiranjeeviyarra/" target="_blank" rel="noopener noreferrer">Prof. Chiranjeevi Yarra</a> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20">
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Oct 3, 2022</th>
                  <td>
                    Paper on <a href="https://ieeexplore.ieee.org/document/10023156" target="_blank" rel="noopener noreferrer">“How Do Phonological Properties Affect Bilingual Automatic Speech Recognition?”</a> accepted at <a href="https://slt2022.org" target="_blank" rel="noopener noreferrer">IEEE SLT 2022</a> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20">
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Sep 10, 2022</th>
                  <td>
                    I will visiting Incheon to attend <a href="https://interspeech2022.org" target="_blank" rel="noopener noreferrer">Interspeech</a>! Happy to meet you if you’ll be attending the same.
<!-- :sparkles: -->
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jul 1, 2022</th>
                  <td>
                    I will be attending <a href="https://2022.naacl.org" target="_blank" rel="noopener noreferrer">NAACL</a> in person. If you are attending too, let’s catch up!
<!-- :sparkles: -->
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jun 19, 2022</th>
                  <td>
                    Submitted my MS Thesis for review <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jun 15, 2022</th>
                  <td>
                    Paper on “Multi-Task End-to-End Model for Telugu Dialect and Speech Recognition” accepted in Interspeech 2022 <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">

<!-- Announcements and news can be much longer than just quick inline posts. In fact, they can have all the features available for the standard blog posts. See below.

***

Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.

#### Hipster list
<ul>
    <li>brunch</li>
    <li>fixie</li>
    <li>raybans</li>
    <li>messenger bag</li>
</ul>

Hoodie Thundercats retro, tote bag 8-bit Godard craft beer gastropub. Truffaut Tumblr taxidermy, raw denim Kickstarter sartorial dreamcatcher. Quinoa chambray slow-carb salvia readymade, bicycle rights 90's yr typewriter selfies letterpress cardigan vegan.

***

Pug heirloom High Life vinyl swag, single-origin coffee four dollar toast taxidermy reprehenderit fap distillery master cleanse locavore. Est anim sapiente leggings Brooklyn ea. Thundercats locavore excepteur veniam eiusmod. Raw denim Truffaut Schlitz, migas sapiente Portland VHS twee Bushwick Marfa typewriter retro id keytar.

> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another.
> —Anais Nin

Fap aliqua qui, scenester pug Echo Park polaroid irony shabby chic ex cardigan church-key Odd Future accusamus. Blog stumptown sartorial squid, gastropub duis aesthetic Truffaut vero. Pinterest tilde twee, odio mumblecore jean shorts lumbersexual. -->
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jun 1, 2022</th>
                  <td>
                    Started working at <a href="https://karya.in" target="_blank" rel="noopener noreferrer">Karya</a> under the mentorship of <a href="https://www.microsoft.com/en-us/research/people/visesha/" target="_blank" rel="noopener noreferrer">Dr. Vivek Seshadri</a> as a Speech/NLP Engineer. 
<!-- :sparkles: -->
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Selected papers -->
          <div class="publications">
            <h2>selected publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div>

        <!-- Entry bib key -->
        <div id="Yadavalli2023SLABERTTP" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT</div>
          <!-- Author -->
          <div class="author">
                  <em>Yadavalli, Aditya</em>, Yadavalli, Alekhya, and Tobin, Vera
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proc. ACL</em> 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/pdf/2305.19589.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker’s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer. To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Mutlilingual Age Ordered CHILDES (MAO-CHILDES) – a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese – to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2]. To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data. Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Yadavalli2023SLABERTTP</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SLABERT Talk Pretty One Day: Modeling Second Language Acquisition with BERT}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yadavalli, Aditya and Yadavalli, Alekhya and Tobin, Vera}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{In Proc. ACL}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2305.19589}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL Findings</abbr></div>

        <!-- Entry bib key -->
        <div id="Moradshahi2023X-RiSAWOZ" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents</div>
          <!-- Author -->
          <div class="author">Moradshahi, Mehrad, Shen, Tianhao, Bali, Kalika, Choudhury, Monojit, Chalendar, Gael, Goel, Anmol, Kim, Sungkyun, Kodali, Prashant, Kumaraguru, Ponnurangam, Semmar, Nasredine, Semnani, Sina, Seo, Jiwon, Seshadri, Vivek, Shrivastava, Manish, Sun, Michael, 
                  <em>Yadavalli, Aditya</em>, You, Chaobin, Xiong, Deyi, and Lam, Monica
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proc. ACL Findings</em> 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://aclanthology.org/2023.findings-acl.174/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Task-oriented dialogue research has mainly focused on a few popular languages like English and Chinese, due to the high dataset creation cost for a new language. To reduce the cost, we apply manual editing to automatically translated data. We create a new multilingual benchmark, X-RiSAWOZ, by translating the Chinese RiSAWOZ to 4 languages: English, French, Hindi, Korean; and a code-mixed English-Hindi language.X-RiSAWOZ has more than 18,000 human-verified dialogue utterances for each language, and unlike most multilingual prior work, is an end-to-end dataset for building fully-functioning agents. The many difficulties we encountered in creating X-RiSAWOZ led us to develop a toolset to accelerate the post-editing of a new language dataset after translation. This toolset improves machine translation with a hybrid entity alignment technique that combines neural with dictionary-based methods, along with many automated and semi-automated validation checks. We establish strong baselines for X-RiSAWOZ by training dialogue agents in the zero- and few-shot settings where limited gold data is available in the target language. Our results suggest that our translation and post-editing methodology and toolset can be used to create new high-quality multilingual dialogue agents cost-effectively. Our dataset, code, and toolkit are released open-source.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Moradshahi2023X-RiSAWOZ</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Moradshahi, Mehrad and Shen, Tianhao and Bali, Kalika and Choudhury, Monojit and de Chalendar, Gael and Goel, Anmol and Kim, Sungkyun and Kodali, Prashant and Kumaraguru, Ponnurangam and Semmar, Nasredine and Semnani, Sina and Seo, Jiwon and Seshadri, Vivek and Shrivastava, Manish and Sun, Michael and Yadavalli, Aditya and You, Chaobin and Xiong, Deyi and Lam, Monica}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{In Proc. ACL Findings}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SLT</abbr></div>

        <!-- Entry bib key -->
        <div id="Shelly2022SLT" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">How Do Phonological Properties Affect Bilingual Automatic Speech Recognition?</div>
          <!-- Author -->
          <div class="author">Jain, Shelly*, 
                  <em>Yadavalli, Aditya*</em>, Mirishkar, Ganesh, and Vuppala, Anil Kumar
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE Spoken Language Technology Workshop</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/document/10023156" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Multilingual Automatic Speech Recognition (ASR) for Indian languages is an obvious technique for leveraging their similarities. We present a detailed analysis of how phonological similarities and differences between languages affect Time Delay Neural Network (TDNN) and End-to-End (E2E) ASR. To study this, we select genealogically similar pairs from five Indian languages and train bilingual acoustic models. We compare these against corresponding monolingual acoustic models and find similar phoneme distributions within speech to be the primary factor for improving model performance, with phoneme overlap being secondary. The influence of phonological properties on performance is visible in both cases. Word Error Rate (WER) of E2E decreased by a median of 2.35%, and upto 8.5% when the phonological similarity was greatest. WER of TDNN increased by 11.69% when the similarity was lowest. Thus, it is clear that the choice of supplementary language is important for model performance.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Shelly2022SLT</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jain, Shelly* and Yadavalli, Aditya* and Mirishkar, Ganesh and Vuppala, Anil Kumar}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Spoken Language Technology Workshop}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{How Do Phonological Properties Affect Bilingual Automatic Speech Recognition?}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">Interspeech</abbr></div>

        <!-- Entry bib key -->
        <div id="Aditya2022Interspeech" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Multi-Task End-to-End Model for Telugu Dialect and Speech Recognition</div>
          <!-- Author -->
          <div class="author">
                  <em>Yadavalli, Aditya</em>, Mirishkar, Ganesh, and Vuppala, Anil Kumar
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proc. Interspeech</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.isca-speech.org/archive/interspeech_2022/yadavalli22_interspeech.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Conventional Automatic Speech Recognition (ASR) systems are susceptible to dialect variations within a language, thereby adversely affecting the ASR. Therefore, the current practice is to use dialect-specific ASRs. However, dialect-specific information or data is hard to obtain making it difficult to build dialect-specific ASRs. Furthermore, it is cumbersome to maintain multiple dialect-specific ASR systems for each language. We build a unified multi-dialect End-to-End ASR that removes the need for a dialect recognition block and the need to maintain multiple dialect-specific ASRs for three Telugu regional dialects: Telangana, Coastal Andhra, and Rayalaseema. We find that pooling the data and training a multi-dialect ASR benefits the low-resource dialect the most – an improvement of over 9.71% in relative Word Error Rate (WER). Subsequently, we experiment with multi-task ASRs where the primary task is to transcribe the audio and the secondary task is to predict the dialect. We do this by adding a Dialect ID to the output targets. Such a model outperforms naive multi-dialect ASRs by up to 8.24% in relative WER. Additionally, we test this model on a dialect recognition task and find that it outperforms strong baselines by 6.14% in accuracy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Aditya2022Interspeech</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yadavalli, Aditya and Mirishkar, Ganesh and Vuppala, Anil Kumar}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Interspeech}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Task End-to-End Model for Telugu Dialect and Speech Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1387--1391}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.21437/Interspeech.2022-10739}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NAACL-SRW</abbr></div>

        <!-- Entry bib key -->
        <div id="Aditya2022NAACLSRW" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Exploring the Effect of Dialect Mismatched Language Models in Telugu
Automatic Speech Recognition</div>
          <!-- Author -->
          <div class="author">
                  <em>Yadavalli, Aditya</em>, Mirishkar, Ganesh, and Vuppala, Anil Kumar
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In North American Chapter of the Association of Computational Linguistics Student Research Workshop</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://aclanthology.org/2022.naacl-srw.36/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Previous research has found that Acoustic Models (AM) of an Automatic Speech Recognition (ASR) system are susceptible to dialect variations within a language, thereby adversely affecting the ASR. To counter this, researchers have proposed to build a dialect-specific AM while keeping the Language Model (LM) constant for all the dialects. This study explores the effect of dialect mismatched LM by considering three different Telugu regional dialects: Telangana, Coastal Andhra, and Rayalaseema. We show that dialect variations that surface in the form of a different lexicon, grammar, and occasionally semantics can significantly degrade the performance of the LM under mismatched conditions. Therefore, this degradation has an adverse effect on the ASR even when dialect-specific AM is used. We show a degradation of up to 13.13 perplexity points when LM is used under mismatched conditions. Furthermore, we show a degradation of over 9% and over 15% in Character Error Rate (CER) and Word Error Rate (WER), respectively, in the ASR systems when using mismatched LMs over matched LMs.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Aditya2022NAACLSRW</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yadavalli, Aditya and Mirishkar, Ganesh and Vuppala, Anil Kumar}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{North American Chapter of the Association of Computational Linguistics Student Research Workshop}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring the Effect of Dialect Mismatched Language Models in Telugu
  Automatic Speech Recognition}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics (ACL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Aditya  Yadavalli. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.
Last updated: October 22, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
